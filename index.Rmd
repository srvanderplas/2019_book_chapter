---
title: "An Introduction to Firearms Examination for Researchers in Statistics"
author: ["Susan VanderPlas", "Alicia Carriquiry", "Heike Hofmann", "James Hamby", "Xiao Hui Tai"]
date: "2019-04-30"
thanks: ["This work was partially funded by the Center for Statistics and Applications in Forensic Evidence (CSAFE) through Cooperative Agreement #70NANB15H176 between NIST and Iowa State University, which includes activities carried out at Carnegie Mellon University, University of California Irvine, and University of Virginia."]
output: 
  pdf_document: 
    citation_package: natbib
    fig_caption: yes
    keep_tex: yes
    latex_engine: pdflatex
    template: template.tex
graphics: yes
header-includes:
  - \usepackage{subfig}
  - \usepackage{amsmath,amssymb}
  - \usepackage[utf8]{inputenc}
bibliography: refs.bib
---

```{r setup, include=FALSE, echo = F}
knitr::opts_chunk$set(echo = F, message = F, warning = F, fig.align = "center", 
                      dev = "CairoPDF", cache = T)
library(imager)
library(x3ptools)
library(bulletxtrctr)
library(cowplot)
library(gridExtra)
library(tidyverse)
```

```{r features-setup}

features <- read.csv("data/H44-old-features.csv")

# f2 <- features %>%
#   tidyr::separate(land1, c("barrel1", "bullet1", "land1"), "-") %>%
#   tidyr::separate(land2, c("barrel2", "bullet2", "land2"), "-")

f2nest <- features %>% filter(!(barrel1==barrel2 & bullet1 == bullet2)) %>%
  group_by( bullet2, barrel1, barrel2, bullet1) %>%  nest()

rotate <- function(x, lag) {
  n <- length(x)
  rep(x, 2)[lag+1:n]
}

f3nest <- f2nest %>% mutate(
  sam_ccf = data %>% purrr::map_dbl(.f=function(d) {
    dt = xtabs(ccf ~land1+land2, data=d)
    drow <- dim(dt)[2]
    1:drow %>% purrr::map_dbl(.f=function(i) {
      mean(diag(dt[,rotate(1:drow,i)]))
    }) %>% max()
  }),
  sam_rf = data %>% purrr::map_dbl(.f=function(d) {
    dt = xtabs(rfscore ~land1+land2, data=d)
    drow <- dim(dt)[2]
    1:drow %>% purrr::map_dbl(.f=function(i) {
      mean(diag(dt[,rotate(1:drow,i)]))
    }) %>% max()
  }),
  sam_rf_phase = data %>% purrr::map_dbl(.f=function(d) {
    dt = xtabs(ccf ~land1+land2, data=d)
    drow <- dim(dt)[2]
    1:drow %>% purrr::map_dbl(.f=function(i) {
      mean(diag(dt[,rotate(1:drow,i)]))
    }) %>% which.max()
  }),
  KM_sam = sam_rf > 0.5
)

inphase <- function(land1, land2, sam_rf_phase, ...) {
  as.numeric(land2) %% 6 == (as.numeric(land1) + sam_rf_phase) %% 6
}

tmp <- unnest(f3nest) %>%
  mutate(inphase = purrr::pmap_lgl(., inphase),
         KM = inphase & KM_sam)
```
# Introduction


In the United States, where firearms are readily accessible, the annual number of gun-related crimes is in the hundreds of thousands, and about two thirds of all murders are committed with a gun \citep{fbi2017}. Almost 400 million guns of all types are owned by civilians, meaning that in the United States, there are about 1.2 guns for every man, woman and child.  Therefore, most crime labs employ one or more experts in firearms examination, who can visually compare striations on bullets or cartridge cases found in a crime scene with those on test shots obtained from the suspect’s gun, or on samples recovered from a different crime scene.

Visual comparisons are problematic for several reasons, including the fact that the assessment of similarity is typically subjective and consequently, estimation of error rates is difficult. This said, establishing a more formal, data-based protocol of the comparison is challenging.  A typical image of a bullet or a cartridge case has tens of thousands of pixels, and a pixel-by-pixel comparison is not robust to changes in scale, rotation, and translation. To add to the challenge, there is no generative model to represent the process by which striations occur that would permit reducing the dimensionality of the images and establishing a formal testing approach.  Finally, it is not clear whether the information contained in the image can be summarized into a set of measurements to enable a data-based comparison. 

Consequently, at the present time, forensic practitioners rely on subjective methods for evaluating and interpreting most types of pattern evidence including striations on bullets and cartridge cases. In a typical evaluation, the examiner compares two or more samples side by side, and conclude that the samples may have a common origin (or source) if the number of common features in the samples warrants "sufficient agreement.  Examiners may rely on instruments such as a comparison microscope and limited measurements of characteristics such as rifling pitch, or examine national databases such as NIBIN \citep{nibin}, but the final decision is almost entirely subjective and greatly depends on the training and experience of the examiner.
The final decision is typically one of identification if the samples are sufficiently similar, exclusion if there are significant dissimilarities, or inconclusive if there are not sufficient features to make a determination. 

As noted in \citet{significance}, the fact that the evaluation of pattern evidence continues to be subjective is problematic. Except for the case of fingerprint examination, there is no agreed upong threshold to declare that two samples are "similar enough". Even among fingerprint examiners, the set of specific minutiae that is used for comparison is common, but there is no rule that establishes the number of matching minutiae that must be exceeded to conclude that two prints have the same origin. Another challenge that arises when the evaluation of evidence relies on subjective methods is that it is impossible to estimate the rate of errors incurred by individual examiners or by the discipline as a whole. Experience is no substitute for experimentation, where ground truth is known \citep{pcast2016}, and therefore, claims by practitioners that the rate of error is zero simply reflect the fact that their conclusions have never been challenged in court or elsewhere.  Finally, when assessments are subjective, it is difficult to estimate the \emph{repeatabilty} and \emph{reproducibility} of firearm evaluations.  Here, we say that an approach is repeatable if the examiner reaches the same conclusion when presented with the same evidence at two different times.  A method is reproducible, if two examiners presented with the same evidence, reach the same conclusion.

Because of these and several other concerns, the \citeauthor{StrengtheningForensicScience2009} assembled a panel of experts who in 2009 published a report that was strongly critical of all forensic disciplines with the exception of DNA analysis of single-donor or simple mixture samples. The report singled out pattern evidence as particularly lacking in scientific validity and rife with subjectivity, and called for an immediate and sustained research effort to shore up pattern evidence by – among other recommendations – developing the scientific and statistical framework that underpin any scientific discipline. Of particular concern for firearms and toolmark analysis is that the process of individualization be "precise and repeatable", in contrast to the current methodological guidelines.

In the last few decades, there have been some attempts to develop methods to quantify the similarity between two bullets or two cartridge cases.  An early attempt by \citet{biasottiStatisticalStudyIndividual1959} consisted of counting the number of consecutively matching striae (CMS) on two bullets.  The idea here is that when two bullets are fired from the same barrel, the number of consecutively matching striations is expected to be high.  While this proposition is likely to be true, the method did not get widely applied in practice because the discriminating power of CMS is limited. \citeauthor{hamby2009} (2009) were the first to assemble an experimental set of bullets that could be used to investigate the reproducibility of firearms examination.  They created 240 replicate sets of 20 reference bullets fired from 10 consecutively manufactured barrels and 15 questioned bullets that were known to have been fired by the barrels in the study.  By now, the 240 sets have been examined by over 700 participating firearms examiners worldwide, 14 of whom have used some form of ballistic imaging technology.  While the design of this experimental dataset would have been improved by, for example, including questioned bullets fired by barrels other than the 10 barrels considered, the database is nonetheless a good resource for researchers. \autoref{fig:HambyCMS}  was drawn using one of the Hamby sets of bullets \citep{hamby2009}.  The set of 20 bullets was fired from 10 consecutively rifled barrels, and the provenance of each bullet (same or different barrel) is known.  We constructed all possible pairs of bullets, some of which came from the same barrel and some of which did not.  The values along the horizontal axis represent the number of CMS, which for this dataset varied from 0 to 25.  For each value of CMS, the two colors on each column represent the proportion of pairs of bullets that had a common (orange) or a different (grey) source. For example, when CMS is equal to 2, 100\% of pairs with 2 CMS had a different source.  When CMS is 10 or higher, 100\% of all pairs of bullets have a common source.  

```{r HambyCMS, fig.cap="Proportion of pairs of bullets with same (orange) or different (grey) source given observed number of CMS.", fig.width = 8, fig.height = 4, out.width = ".75\\textwidth"}
tmp %>%
  mutate(
    lys = overlap*signature_length*1000/.645,
    CMS = round(cms2 *lys*.645/1000)
  ) %>%
  mutate(km_lab = c("Non-Match (KNM)", "Match (KM)")[KM + 1]) %>%
  filter(!(!KM & CMS > 10)) %>% # Exclude bad hamby bullets that show as nonmatches
ggplot(data = .) + 
  geom_bar(aes(x = CMS, fill = km_lab), position = "fill", color = "grey20") +
  scale_y_continuous("Proportion") + 
  scale_x_continuous("Consecutive Matching Striae (CMS)") +
  scale_fill_manual("", values = c("Non-Match (KNM)" = "darkgrey", "Match (KM)" = "darkorange")) + 
  theme(legend.position = "top", legend.justification = 'center')
```

From the figure, it seems that -- at least for this particular dataset -- when the observed number of CMS is between 4 and 10, a binary decision of same/different source has a non-negligible probability of being incorrect.

In recent years, there has been a push to develop more robust methods to address the question of source.  Much of the effort has been devoted to cartridge cases:  breech face impressions, firing pin impressions, firing pin aperture.  We describe some of these approaches later in this chapter.  Less attention has been devoted to bullets, perhaps due to the fact that bullets sometimes get damaged on impact and this makes the comparison more difficult. In both cases, methods based on machine learning and computer vision have gained in popularity among researchers and appear to be promising for use in case work. 

Machine learning can be used to augment the subjective perceptions of examiners, providing a quantitative foundation for the assessment of questions of source in firearms examination. In order to leverage machine learning techniques for firearm identification, researchers mostly use supervised learning algorithms and large amounts of labeled training data, called a training set, to assess how features from the data relate to the labels. From the training set, the algorithm "learns" how the features relate to the labels, or in other words, produces an estimate of the function that describes the association between features and label. Once the algorithm has been trained, it can be used to examine new data outside the original training set. 

A good algorithm strikes a balance between the competing objectives of optimizing its performance on the training data while at the same time, minimizing classification errors when presented with new units. This is known as the variance-bias tradeoff; more flexible models, that fit the training data very well, have high variance, because even a small change in the data might result in a large change in the fitted model. On the other hand, models that fit the training data less closely, may be more robust to changes in the observations, but tend to exhibit a larger bias. Often, when labels are discrete, the learning algorithm is known as a classifier because it is typically used to classify units into different classes. 

This chapter is intended for an wide audience that might include statisticians interested in doing research in the area of firearms examination, or for lawyers and judges who wish to understand the current state of the discipline.  The chapter is organized as follows.  We first provide a brief description of firearms and ammunition and introduce some of the language used in firearm examination.  We then briefly revisit the history of the discipline of firearms examination. The next two sections describe the new methodology for bullet and cartridge case comparisons and where the science is likely to go next.  We finish with a partial list of knowledge gaps and opportunities for research.  

# The anatomy of guns and of ammunition 

About 12.5 million guns were manufactured in the United States in 2016, of which approximately 50\% were pistols or revolvers.  In the same year, the United States imported slightly over five million firearms, the vast majority of which were handheld pistols and revolvers. Here we briefly describe the components and operation of pistols and revolvers, since according to the FBI \citep{fbi2017} over 70\% of all gun-related crimes involve one of those types of firearms.

The main difference between a revolver and a pistol is the mechanism to load ammunition into the \emph{chamber}.  In a revolver, cartridges are loaded into their own chamber in a cylinder that rotates when the hammer is cocked and the trigger is pulled (in \emph{single-action} revolvers) or advances with just the pull of the trigger (\emph{double-action}).  The capacity of the cylinders tends to be limited to six cartridges, and cartridges are not ejected from the cylinder each time the revolver is fired.  In a pistol, cartridges are loaded into a \emph{magazine} that can contain anywhere between 5 and 18 rounds, depending on caliber and type of magazine.  Pistols are self-loading firearms because a fresh cartridge from the magazine is automatically moved into the single chamber when the \emph{slide} of the gun is pulled rearward. The spring-loaded slide then returns forward, feeding the first cartridge into the chamber for firing.  The pistol is fired with each new pull of the trigger, and the next cartridge in the magazine is moved into the chamber.  This is why this type of firearm is known as a \emph{semi-automatic} weapon.  In contrast to what happens when a revolver is fired, cartridge cases are ejected from the barrel of a pistol at the time of firing \citep{heard1997}. \autoref{fig:cutaway} shows a Luger 1901 pistol cutaway with important parts labeled.

\begin{figure}
\centering
\includegraphics[width=.7\textwidth]{figure/Luger-Cutaway.png}
\caption{A 1901 Luger pistol. Image modified from Rock Island Auction Co. [CC0], via Wikimedia Commons (\url{https://commons.wikimedia.org/wiki/File:Luger_cutaway.jpg})\label{fig:cutaway}}
\end{figure}

<!--
```{r pistol, eval = F, fig.cap = "Simple diagram of a semi-automatic pistol. \\footnotesize{Image modified from \\href{https://XXXXXXXXXXX}.", out.width = ".5\\textwidth"}
knitr::include_graphics("figure/semi-automatic-gun.png")
```
-->

When the firearm is fired, several things occur.  First, the firing pin hits the primer at the base of the cartridge, causing a small explosion that ignites the propellant.  As it burns, the propellant creates  gas inside the cartridge case.  The tremendous change in pressure inside the cartridge case separates the bullet from the cartridge and pushes it down the barrel at a speed anywhere between 200 to 650 m/s, depending on caliber.  Most barrels are \emph{rifled}, meaning that their interior has grooves and elevated surfaces between the grooves called lands (typically five or six of each) at a left or right angle, and this imparts rotation to the bullet as it travels down the barrel.  This improves stability in the flight of the bullet.  Consequently, fired bullets also show a pattern of land impressions and grooves that correspond to the rifling of the barrel.  In addition to separating the bullet from the cartridge, the explosion caused by the accumulation of gases in the cartridge case makes the base of the cartridge case slam against the breech face of the pistol. Cartridge cases in semi-automatic pistols are typically ejected once the bullet is separated. \autoref{fig:WikiAmmo} shows a diagram of a cartridge. 


\begin{figure}
\centering
\includegraphics[height=.25\textheight]{figure/WikiAmmo.png}
\caption{Diagram of a cartridge with its components:  (1) bullet, (2) cartridge case, (3) propellant or powder, (4) base of the cartridge case, and (5) primer. \footnotesize{Image downloaded from Wikipedia (\url{https://en.wikipedia.org/wiki/Bullet})}}
\label{fig:WikiAmmo}
\end{figure}

<!--
\begin{figure}
\centering
\includegraphics[width=.4\textwidth]{figure/CartridgeCase.png}\includegraphics[width=.4\textwidth]{figure/Bullet.png}
\caption{Left panel:  Bottom of a cartridge case.  EM denotes ejector marks, FP denotes firing pin impression and BF denotes breech face impressions. Right panel: Bullet showing engraved land areas and groove impressions. \\footnotesize{Cartridge case image downloaded from NIST, (\\url{https://commons.wikimedia.org/wiki/File:Cartridge_Case_(7788259910).jpg})}.}
\label{fig:marks}
\end{figure}
-->

# A Brief History of Firearms Examination

<!-- Not the first - 1835 Bow Street Runners case in London (homemade ammunition matched to a mold) -->
Firearms examination has been practiced for a long time.  The discipline is sometimes incorrectly referred to as \emph{ballistics}; the term ballistics is more appropriately associated with flight and impact properties of projectiles once they are fired.  Its first recorded use around 1835 is attributed to the Bow Street Runners, the first police-like force in London, precursor of the Metropolitan police \citep{beattie}
. \citet{wilson2003written} tell the story of Confederate General Jackson, who was killed in battle in 1863, during the Civil War. The fired bullet recovered from his body was examined and found to be a 0.67-caliber ball, the type of ammunition used by Confederate, not by Union soldiers, leading to the surprising conclusion that General Jackson had been killed by one of his own men. 

In \citeyear{hallMissileWeapon1900}, a paper by \citeauthor{hallMissileWeapon1900} published in the Buffalo Medical Journal detailed methods for test firing weapons (into a bag of meal) for the purposes of comparing the engravings resulting from the rifling. While it is not clear from the paper whether the comparisons made are class characteristics (e.g. the spacing of land and groove engraved areas) or individual characteristics, this represents the first known foray into what might be termed "modern" examinations of fired bullets. In 1902, testimony concerning the markings on bullets was admitted into evidence \citep{commonwealthVbest} in a criminal case for the first time, and in 1907, fired cartridge cases were also used as evidence \citep{brownsvilleRiot}. In 1912, photographic comparisons were used to examine individualized markings of land and groove engraved areas; enlarged photographs were also used to compare cartridge case marks. In the 1920s, the idea that individualizing characteristics are present on fired bullets and cartridges became more widely accepted across the country, accompanied by an increase in court cases involving evidence from bullets and cartridge cases. The uniqueness of striations or other marks is impossible to prove, but it seems clear that marks carry information about the firearm that fired the ammunition. A thorough historical review of the discipline of firearms examination can be found in \citep{hamby-thorpe-1999}.


The process of comparing the striations of bullets recovered from a crime scene to test-fired bullets from recovered weapons became much more practical in 1925 with the invention of the comparison microscope, which allowed two bullets to be examined simultaneously and manually aligned \citep{afte-examiner-training}. \autoref{fig:comparison-scope} shows an early model of a comparison microscope; portions of both bullets under examination are shown in a single unified view window. The same year, a series of two articles in the Saturday Evening Post described the potential uses of firearms examination in popular press \citep{BulletsExpertWitness,BulletsSilentWitness}, increasing the public's awareness of the potential of firearm forensics. Five years later, Goddard would testify about the firearms used in the Valentine's Day Massacre \citep{goddardValentineDayMassacre1930}; this testimony included analysis of the cartridge cases recovered from the scene as well as the markings left on the bullets. 

```{r comparison-scope, fig.cap = "A comparison microscope, which consists of two identical microscopes connected to a single eyepiece. The viewer sees the images of both bullet surfaces simultaneously, facilitating alignment and comparison of the bullet striae, shown in the inset image.", out.width = ".7\\textwidth"}
knitr::include_graphics("figure/ComparisonMicroscope.png")
```

Firearms examination became more of a discipline in the 1930s, with textbooks published on the subject in both the UK and the United States \citep{burrard1934identification,hatcherTextbookFirearmsInvestigation1935,gunther1935identification}. The 1930s also saw the foundation of a number of laboratories focused on the scientific examination of forensic evidence, a trend that continued into the 1940s. In the 1950s and 1960s, the field began to move toward greater quantification of firearms evidence, with the introduction of the striagraph \citep{davis1968introduction}, an early forerunner of laser and digital scanning of bullets. In \citeyear{biasottiStatisticalStudyIndividual1959}, \citeauthor{biasottiStatisticalStudyIndividual1959} published a landmark paper discussing the use of visual features of pairwise bullet comparisons to produce a quantitative description of the strength of the match between the two bullets. Biasotti examined the striation marks on fired bullets under a virtual comparison microscope and determined that consecutive matching striations could be used to determine the strength of a match between two bullets which were aligned based of visual assessment of striation patterns. Based on a sample of bullets fired from 24 Smith \& Wesson revolvers, Biasotti determined that bullets fired from different guns were extremely unlikely to have more than 6 consecutively matching striae. This quantitative threshold for determining whether two pieces of evidence originate from the same firearm was the first attempt to derive an empirical threshold for the strength of a match in firearms examination. 

Some methods have been developed to automatically match high-resolution photographs of bullet land engraved areas or cartridge cases \citep{gardnerComputerIdentificationBullets1978,geradtsImageMatchingAlgorithms2001}, but in the past 20 years or so there has been a push to use 3D imaging technology to obtain actual measurements of the surface topology of land engraved areas on bullets and of cartridge case bases. Methods which depend on photographs rely on inferring the height of the surface from the color of the image pixels; topological measurements provide much greater precision in assessing the similarity of two samples. One of the first proponents of measuring features of the surface topology of bullets were \citet{dekinderAutomatedComparisonsBullet1999}. The authors used a laser profilometer to scan bullets and obtain measurements of the distance and depth of striations. They then computed a correlation between two aligned sets of features to quantify the similarity between two bullets. Since then, several new methods that rely on 2D and 3D imaging of bullets and cartridge cases have been proposed to quantify the similarity between two items \citep{tongFiredCartridgeCase2014,fischerDigitalCrimeScene2014,chumbleyValidationToolMark2010}. In 2017, \citeauthor{hare2017algorithmic} demonstrated the use of supervised learning algorithms to construct a similarity score that can be used to assess the strength of a match between two bullets quantitatively, and \citet{taiFullyAutomaticMethod2018} constructed a similar scoring algorithm for cartridge case comparison.

## Microscopic Imperfections


Forensic examiners will begin an examination of crime scene evidence by identifying class characteristics, such as ammunition type, rifling, number of grooves, shape of the firing pin and other features shared by many different guns and bullets; the second stage of the process is to establish whether a bullet was fired by a specific gun using individualizing characteristics. Most automatic algorithms bypass the comparison of class characteristics and only examine the microscopic  individual striations that uniquely identify a specific barrel. The left panel of \autoref{fig:marks} shows the engraved areas left behind by the lands and grooves of the barrel on the bullet. Small imperfections in the surface of the barrel create striations on the bullet as it leaves the gun. Marks are also imprinted to the base of the cartridge case by the breech face of the gun at the time it is fired; these marks can also be compared through a similar process. The right panel in Figure \ref{fig:marks} shows a cartridge case with breech face, firing pin and ejector marks. Firearms examiners tend to focus on the breech face impressions because they appear to be the most discriminating. 


\begin{figure}
\centering
\includegraphics[width=.3\textwidth]{figure/Bullet.png} \includegraphics[width=.3\textwidth]{figure/CartridgeCase.png}
\caption{Left panel: Bullet showing engraved land areas and groove impressions. Right panel:  Base of a cartridge case.  EM denotes ejector marks, FP denotes firing pin impression and BF denotes breech face impressions.  \footnotesize{Cartridge case image downloaded from NIST, via Wikimedia Commons (\url{https://commons.wikimedia.org/wiki/File:Cartridge_Case_(7788259910).jpg})}.}
\label{fig:marks}
\end{figure}

It was only during the past few years that the role of statistics in firearm and toolmark examination began to surface. Before researchers started collecting 2D and 3D images of cartridge cases and bullets, there were no data to analyze and the few experiments that were conducted did not include a rigorous experimantal design phase.  Indeed, there was no discussion of the potential benefits of using principled quantitative analysis among firearm and toolmark examiners until the NRC published its report \citep{StrengtheningForensicScience2009}.  The recommendations in the report, plus the gradual acceptance of a likelihood ratio framework for the interpretation of evidence in other forensic disciplines encouraged several research groups to begin designing experiments and collecting data, developing algorithms for classification and matching \citep{riva-champod-2014,zheng2014,vorburger2015}, and proposing approaches to approximate likelihood ratios via empirical score-based ratios \citep{hare2017algorithmic,song2018,taiFullyAutomaticMethod2018}. We review some of this work in the next two sections.

# Comparison of cartridge case marks

With the advent of high resolution 2D and 3D microscopy, researchers in the last two decades have proposed several new methods to quantify the similarity between two bullets or cartridge cases.  Much of the research has focused on cartridge cases rather than bullets, probably because bullets tend to get damaged on impact and are recovered with lower frequency (NRC, 2008). A partial list of the research results presented in the last two decades includes \citet{bachrach2002}, \citet{vorburger2011}, \citet{weller2012}, \citet{song2013}, \citet{chu2013}, \citet{riva-champod-2014}, \citet{zheng2014}, \citet{vorburger2015}, and \citet{song2018}. 

\citet{song2018} review a method called Congruent Matching Cells (CMC) to compare the breech face impressions on two cartridge cases.  The data with which the authors work are 3D images of breech face markings on the base of cartridge cases, obtained via confocal microscopy. The comparison method consists in first dividing the reference sample into a grid of cells and then implementing an automated search for the closest matching areas on the questioned sample.  \autoref{fig:CMC} illustrates the method.  In the figure, the left panels show the same cartridge case base A with a sequence of cells defined on a regular grid by the user. Note that jointly, the cells cover most of the breech face marked area.  The two right panels show  cartridge case  B, to be compared to cartridge case A.  On the top right panel, B appears to match A;  after some rotation, it is possible to find congruent cells in B for almost all cells in A.  In contrast, the image on the bottom right panel illustrates what happens when the two cartridge cases were fired from different guns.  Even after systematically rotating image B by small increments of two degrees, it is not possible to fnd cells in B to correspond to the cells in A.  

<!--
```{r CMC, fig.cap = "The Congruent Matching Cells method. Known sample is shown in the left panel and questioned sample is shown on the right panel. \\footnotesize{Image copied from \\citeauthor{song2018}\\href{https://doi.org/10.1016/j.forsciint.2017.12.013}", out.width = ".5\\textwidth"}
knitr::include_graphics("figure/CMCFig2Song2018.pdf")
```
-->

\begin{figure}
\centering
\includegraphics[width=.8\textwidth]{figure/NIST-CMS.png} 
\caption{The method of Congruent Matching Cells.  Top two panels illustrate the case where the two cartridge cases were fired from the same gun. The bottom two panels show an example of two cartridge cases fired from different guns.  \footnotesize{mage downloaded from NIST, (\url{https://www.nist.gov/news-events/news/2018/02/how-good-match-it-putting-statistics-forensic-firearms-identification})}.  }
\label{fig:CMC}
\end{figure}


The number of CMC can be thought of as a \emph{score};  when two cartridge cases are fired from the same gun, we expect to see a larger number of CMC than when the rounds were fired from different guns.  To establish a threshold number of CMC to conclude that the samples were indeed fired from the same gun, the authors obtain the empirical distribution of the number of CMC among pairs of cases known to have been fired by the same gun and pairs of cases known to have been fired by different guns.  Their method is promising in that the empirical distributions, at least for the cases they have considered, put mass on distinctly different ranges of number of CMC for known matching and known non-matching pairs of cases.

Instead of dividing the image into cells, a common alternative is to use a global measure of similarity between two images, for example the correlation between the corresponding pixels in the two images. In order for such methods to work, a series of processing and alignment steps is required. These  methods are described by \citet{Tai-Eddy-2018} for the case of 2D cartridge case images.

The first step in the pre-processing of the image is to select parts of the image that are of interest, in this case the breechface marks. This involves removing the firing pin impression, and any other extraneous details outside of the perimeter of the breechface marks. This can be done automatically either using image processing techniques, or in 3D by fitting a plane to the breechface area and setting a distance threshold beyond which information is discarded. Next, the image is further processed to highlight distinguishing features and remove sources of inaccuracies. For example, a Gaussian filter is commonly applied, which roughly corresponds to highlighting individual characteristics that examiners look for, while removing noise from the image acquisition process.

After pre-processing, a pair of images needs to be aligned to each other before a similarity score can be extracted. Assuming that images have been captured in a roughly similar manner, as is usually the case with equipment used in forensic laboratories, three parameters need to be estimated: the rotation angle, horizontal translation and vertical translation. This can be done using a grid search, looking for the set of parameters that maximizes the similarity measure. Other optimization techniques, such as the Lucas-Kanade algorithm \citep{Lucas-Kanade-1981}, often used in object tracking in the computer vision literature, have also been tested. These have the advantage of much shorter run-times compared to a grid search, but often get stuck in local minima, thus producing poorer overall results.

\citet{Tai-Eddy-2018} test the above methods on various publicly available data sets maintained by NIST (https://tsapps.nist.gov/NRBTD/), and illustrate some of the results. Each data set contains a varying number of breech face images, collected for different purposes by groups in the firearms and toolmarks community. For example, a set called the NIST Ballistics Identification Database Evaluation (NBIDE) has images from 144 cartridge cases generated from three gun types (Sig Sauer, Ruger, and Smith \& Wesson), four guns of each type, four ammunition types (Remington, Winchester, PMC, and Speer), and firing three repetitions for each ammunition type. Both 2D images (using reflectance microscopy) and 3D topographies (using confocal microscopy) were captured. Given these 144 cartridge cases, there are a total of 10,296 pairs of cartridge cases, meaning that the procedure for pairwise alignment needs to be done 10,296 times. Since these data were collected as part of an experiment, the ground truth for whether each pair of images comes from the same gun is known, and \citet{Tai-Eddy-2018} can generate plots of the empirical distribution of similarity scores for matching and non-matching pairs. These empirical distributions are shown in \autoref{fig:NBIDEscores}. As we can see, non-matching pairs generally have low similarity scores, while matching pairs have either low or high scores.


```{r NBIDEscores, fig.cap = "Distribution of similarity scores for matching and non-matching pairs for the NBIDE data set. \\footnotesize{Image provided by  X-H Tai.}", out.width = ".8\\textwidth"}
load("data/removedDupsNBIDE.Rdata")
removedDups %>%
  mutate(match_fact = factor(match, levels = c(0, 1), labels = c("Non-Match (KNM)", "Match (KM)"))) %>%
ggplot() + 
  geom_density(aes(x = corrMax, fill = match_fact), alpha = 0.75) + 
  scale_fill_manual("", values = c("Non-Match (KNM)" = "darkgrey", "Match (KM)" = "darkorange")) + 
  scale_x_continuous("Maximum Correlation") + scale_y_continuous("Density") + 
  theme(legend.position = c(1, 1), legend.justification = c(1, 1))
```


If the problem of interest is to predict whether a specific pair of cartridge cases have the same source, we need to select a cutoff for the similarity score, above which we classify the pair to be a match. If distributions of similarity scores for matching and non-matching pairs were clearly separated for all data sets, such a cutoff would be straightforward to determine, but as we see in \autoref{fig:NBIDEscores}, this is not the case. \citet{Tai-Eddy-2018} consider different cutoffs, and illustrate the results using precision and recall graphs in \autoref{fig:NBIDEprecRec}. As a reminder, \emph{precision} refers to the proportion of true matches among pairs that the algorithm predicted to have a common source, and \emph{recall} is the proportion of same source pairs that were identified as such by the algorithm. A good reference for hierarchical clustering and the various linkage methos is \citet{johnson}.

```{r NBIDEprecRec, fig.cap = "Precision and recall for various cutoffs on the similarity score. Additionally, precision and recall are also calculated for different cutoffs using different linkage methods in hierarchical clustering.. \\footnotesize{Image provided by  X-H Tai.}", out.width = ".8\\textwidth"}
# knitr::include_graphics("figure/NBIDEprecRec.png")

load("data/prNBIDE.Rdata") # original line
load("data/prNBIDElinks.Rdata") # linkages
pr <- as.data.frame(pr)

calcAUC <- function(data) {
  DescTools::AUC(c(1, data$recall, 0), c(0, data$precision, 1))
}

pr_full <- bind_rows(
  tibble(
    link = "Original",
    numClusters = NA,
    precision = pr$precision,
    recall = pr$recall,
    order = 1:nrow(pr)
  ),
  precRecall %>%
    group_by(link) %>%
    arrange(numClusters) %>%
    mutate(order = dplyr::row_number())
)

matlab_colors <- c(rgb(0.9290, 0.6940, 0.1250),
                   rgb(0.4940, 0.1840, 0.5560),
                   rgb(0.4660, 0.6740, 0.1880),
                   rgb(0.3010, 0.7450, 0.9330),
                   rgb(0.6350, 0.0780, 0.1840))

pr_full_auc <- pr_full %>% nest(-link, .key = 'roc') %>% 
  mutate(auc = purrr::map(roc, calcAUC),
         label = sprintf("%s (AUC = %0.2f)", str_to_title(link), auc)) %>%
  unnest(roc) %>%
  mutate(link = factor(link, levels = c("Original", "minimax", "average", "complete", "single"), ordered = T)) %>%
  arrange(link, order) %>%
  mutate(label = factor(label, levels = unique(label)))

ggplot() + 
  geom_path(aes(x = recall, y = precision, color = label), data = pr_full_auc, size = 1.5) + 
  scale_x_continuous("Recall (TP/Actual Positive)") + scale_y_continuous("Precision (TP/Predicted Positive)") + 
  ggtitle("Precision vs. Recall") + 
  scale_color_manual("", values = matlab_colors) + 
  theme(legend.title = element_blank(), legend.position = c(0, 0), legend.justification = c(0, 0))

```

In actual cases, forensic practitioners may have multiple cartridge cases to compare, so the issue of 
the transitivity of matches becomes important. Given that we are considering pairs of images, a classification method might produce the result that A matches B and B matches C, while A does not match C. In order to resolve this problem, \citet{Tai-Eddy-2018} propose using hierarchical clustering on the pairwise results, with various types of linkages  \citep[see][]{murtagh}. In the example above, using single linkage would simply add a link between A and C, concluding that A, B and C all come from the same gun. Results observed after applying various clustering techniques to the similarity scores obtained by \citet{Tai-Eddy-2018} are also plotted in \autoref{fig:NBIDEprecRec}; average and minimax linkage produce the best results in terms of precision and recall on the NBIDE data set.

We conclude this section with several comments as well as suggestions for future research directions. In an actual implementation of the type of methodology described above, one might select cutoffs depending on the type of performance desired. For example, in a criminal case where the defendant might be implicated and prosecuted, false positives could be more undesirable than false negatives, in which case we might like a very high level of confidence in a conclusion of same source. If such a method is simply used to generate investigative leads, we might instead prefer high recall. Also, regardless of the type of algorithm used for comparing two breech face marks, different data sets produce varying quality of results (see, e.g., Figures \autoref{fig:NBIDEscores} and \autoref{fig:NBIDEprecRec}). This is roughly consistent with observations by examiners that some gun brands or ammunition types produce varying quality of marks. Finally, in light of the criticism of subjectivity in pattern matching techniques, any algorithm that is fully automatic and produces reliable and reproducible results would be highly desirable. Before any one approach is selected for application in real case work, it will be critical to continue testing and fine-tuning the different approaches that have been proposed, and that look promising.


# Comparison of marks on land engraved areas of bullets

For most rifling types, fired bullets exhibit a sequence of land engraved areas separated by grooves. The striations that are used to compare bullets appear on the land engraved areas, so the measurements are obtained by scanning each area individually. Measurements on a land engraved area consist of heights on an $xy$ grid in micron-level increments. The exact resolution at which images are taken depends on the microscope. In \citet{hare2017algorithmic}, scans made available through the NIST Ballistics Research Database were used to develop their algorithm. These scans are taken at a resolution of $1.5625 \mu m \times 1.5625\mu m$. The total area that is captured from each land engraved area is approximately $2.2 mm \times 0.6 mm$, and the data are the $xyz$  coordinates of each point on the grid. For one land engraved area, the dimension of the $xy$ matrix is $507 \times 1001$, which means that the number of $z$-values obtained for each land engraved area is slightly over half a million.  For an entire bullet with six land engraved areas, the dataset has more than three million measurements. Data files in the format just described can be downloaded from the NIST ballistics database \citep{NISTdata}. Figure 9 shows the 3D scan of a land engraved area of a bullet fired from a Smith & Wesson firearm. Well pronounced striations can usually be found  close to the bottom of the bullet, in the area shaded in darker gray in the figure.

```{r generate-bullet-renders}
x3pfile <- read_x3p(file = "data/HS36-B1-B1-L1.x3p")
x3pfileb2 <- read_x3p(file = "data/HS36-B1-B2-L4.x3p")

# Interpolate a bit using imager - fill in holes in places where they're small
x3pfile2 <- x3pfile
x3pfile2$surface.matrix %<>% as.cimg() %>% inpaint(5) %>% as.matrix()
na_mask <- x3pfile$surface.matrix %>% is.na() %>% as.cimg() %>% clean(20)
na_mask2 <- na_mask %>% grow(30) %>% shrink(27)
x3pfile2$surface.matrix[na_mask2] <- NA

x3pfile2b2 <- x3pfileb2
x3pfile2b2$surface.matrix %<>% as.cimg() %>% inpaint(5) %>% as.matrix()
na_maskb2 <- x3pfileb2$surface.matrix %>% is.na() %>% as.cimg() %>% clean(20)
na_mask2b2 <- na_maskb2 %>% grow(30) %>% shrink(27)
x3pfile2b2$surface.matrix[na_mask2b2] <- NA

# image_x3p(x3pfilter, file = "figure/HS36-B1-nocrosscut.png", size = c(3577, 1023))
# image_x3p(x3pfile2b2, file = "figure/HS36-B2-nocrosscut.png", size = c(3607, 1023))

crosscut <- x3p_crosscut(x3pfile2)
nomask <- x3p_add_mask(x3pfile2, matrix("#cd7f32", ncol = 3577, nrow = 1023))
hline <- x3p_add_hline(nomask, yintercept = unique(crosscut$y - 100), color = "darkred", size = 40)
# image_x3p(hline)
# x3p_snapshot(file = "figure/HS36-Bullet-With-Crosscut.png")


x3pdf <- x3p_to_df(x3pfile)
x3pdf_filter <- filter(x3pdf, y > 150)
x3pfilter <- df_to_x3p(x3pdf_filter)

grooves <- list(groove = c(110, 2120))
signature <- cc_get_signature(crosscut, grooves)

# image_x3p(x3pfilter, multiply = 3)
# 
# pmat <- structure(c(0.9976, -0.00916, 0.06750, 
# 0, 0.0681, 0.1071, -0.9919, 
# 0, 0.00185, 0.99420, 0.1075, 0, 
# 0, 0, 0, 1), .Dim = c(4L, 4L))
# rgl::par3d(userMatrix = pmat)
# x3p_snapshot(file = "figure/HS36-Bullet-With-Crosscut_rotate90.png")

```

```{r bullet-scan-crosscut-image, fig.cap = "Scanned surface of a bullet land engraved area. Striations in the area shaded in red are well pronounced and informative for the matching process.", out.width = ".8\\textwidth"}
knitr::include_graphics("figure/HS36-Bullet-With-Crosscut.png")
```

The algorithm proposed in \citet{hare2017algorithmic} uses the average height of striations on a set of consecutive cross-sections of the land engraved area at a specific value of $y$.  This value is determined automatically, by computing the cross-correlations among heights at consecutive cross-sections and selecting the coordinate $y$ at which the cross-correlations are less variable. This is the area on the land wher striations appear to be most stable. \autoref{fig:bullet-scan-crosscut-image} shows the selected value of $y$ for a land engraved area scan. \autoref{fig:bullet-scan-crosscut-side-view} shows the same scanned area as in \autoref{fig:bullet-scan-crosscut-image}, but viewed as a cross-section where $y$ is fixed. The bottom panel is a single-pixel representation of the cross-section shown in the upper panel. In both panels, it is evident where the land engraved area begins and ends, but in some cases, finding the grooves in an automated way is challenging.

The dominant feature in the top panel of \autoref{fig:bullet-scan-crosscut-side-view} is the curvature of the surface of the land engraved area.  This structure is so pronounced that the striations appear to be negligibly shallow. In order to bring the striations to the forefront, the first step in the algorithm proposed by \citet{hare2017algorithmic} is to subtract the curvature from the image by fitting a local polynomial regression model via Loess (\citet{loess}).  The residuals from the Loess function represent the  striations and comprise the data that will be used to construct a signature. \autoref{fig:bullet-remove-curvature} shows the fitted curve in blue in the top panel, and the Loess residuals in the bottom panel. Note the difference in scale of the two figures; the range of heights of the land engraved area on the top panel is about 120$\mu$m, while  the range of the residuals shown in the bottom panel is approximately 6$\mu$m. For some combinations of ammunition and gun, the striations are shallower.

```{r bullet-scan-crosscut-side-view, fig.cap =  "Sideways view of the scan from Figure 3 (top), with height measurements across the red shaded area (bottom).", out.width = ".8\\textwidth"}
plot_grid(
  ggdraw() + draw_image("figure/HS36-Bullet-With-Crosscut_rotate90.png"), 
  ggplot(aes(x = x, y = value), data = filter(x3pdf, abs(y - 329.595) < 10)) +
    geom_point(size = 0.5) +
    theme_bw() +
    coord_fixed(ratio = 3) +
    xlab("x") +
    ylab("z"),
  nrow = 2
)
```

```{r bullet-remove-curvature, fig.cap = "Loess fit to remove curvature shown in blue (top). Residuals from the Loess fit (bottom) show the relative heights of the engraved striae.", out.width = ".8\\textwidth", fig.width = 8, fig.height = 4}
p1 <- ggplot(aes(x = x, y = value), data = filter(x3pdf, abs(y - 329.595) < 2)) +
  geom_point(size = 0.5) +
  geom_smooth(aes(x = x, y = value), data = filter(x3pdf, abs(y - 329.595) < 10, x > 110, x < 2120)) +
  theme_bw() +
  xlim(c(0, 2300)) +
  xlab("Relative Location (in \u03BCm)") +
  ylab("Scan Height (in \u03BCm)") +
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), 
        axis.text.y = element_text(angle = 90), 
        plot.margin = margin(b = 0, unit = "pt"))

p2 <- ggplot(aes(x = x, y = sig), data = signature) +
  geom_line(size = 0.5) +
  theme_bw() +
  xlim(c(0, 2300)) +
  xlab("Relative Location (in \u03BCm)") +
  ylab("Signature (in \u03BCm)") +
  theme(plot.margin = margin(b = 0, unit = "pt"), 
        axis.text.y = element_text(angle = 90))

grid.arrange(p1, p2, nrow = 2, heights = c(1, 1.2))
```

## Pairwise Comparisons

The signature of a land engraved area is in the form of a text file with the ordered depth of the striae.  The location at which each depth was measured can be inferred from the relative location of the measurement in the file and the size of the step between one measurement and the next. The question of interest is whether signatures extracted from a land engraved areas from two different bullets are similar enough to suggest that the bullets were fired from the same barrel. To quantify the degree of similarity between two signatures, \citet{hare2017algorithmic} propose overlaying the signatures and then computing several different features that represent the distance between the two signatures. For example, it is possible to compute a cross-correlation between two signatures, or to measure differences in the height of peaks or depth of valleys. \citet{hare2017algorithmic} define several different features that can be quantified and used to decide whether the signatures are similar enough to suggest that the bullets may have been fired from the same barrel. \autoref{fig:overlaid-signatures} shows the overlain signatures for two bullets that were fired from the same barrel. Even though the signatures are not exactly the same, they are \emph{similar enough} to suggest that they may have a common source. We revisit the definition of "similar enough" later in this chapter.

```{r overlaid-signatures, fig.cap = "Overlaid signatures of two bullets fired from the same gun.", out.width = ".8\\textwidth"}
crosscut2 <- x3p_crosscut(x3pfileb2)
grooves2 <- list(groove = c(175, 2100))
signature2 <- cc_get_signature(crosscut2, grooves2)


align <- sig_align(signature$sig, signature2$sig)
aligndf <- align$lands %>%
  gather(key = type, value = sig, -x)

ggplot(aes(x = x, y = sig, linetype = type), data = aligndf) +
  geom_line(size = 0.5) +
  theme_bw() +
  xlim(c(0, 2300)) +
  xlab("Relative Location (in μm)") +
  ylab("Signatures (in μm)") +
  theme(plot.margin = margin(b = 0, unit = "pt")) +
  scale_linetype_discrete(guide = F)
```

\citet{hare2017algorithmic} extracted seven features from the overlain signatures; to explore whether any of them would serve to accurately determine whether two bullets could have been fired from the same gun, they carried out the following experiment. First, they obtained 3D images of bullets that were fired by Hamby et al. using 10 consecutively rifled 9mm Ruger barrels.  The data consisted of two bullets known to have been fired by each of the 10 barrels, plus 15 "unknown" bullets, where we know that at least one and no more than three were fired by each of the test barrels. The design of this study has been critized \citep{pcast2016} because it is \emph{closed}, meaning that after the first few comparisons, the number of candidates becomes smaller and smaller. Next they constructed all possible pairs of images of land engraved areas, resulting in a total of 10,384 pairs of lands; of these, 172 pairs corresponded to the same land on bullets fired from the same barrel, and the rest (10,212) corresponded to either different pairs of land engraved areas on bullets fired from the same barrels or to pairs of land engraved areas on bullets fired from different barrels.  Two damaged lands were excluded from the comparisons. Then, for each pair of images \citet{hare2017algorithmic} computed the value of each of seven features; the distribution of values of each of the features among pairs of known matching land engraved areas and among pairs of known non-matching land engraved areas are shown in \autoref{fig:empirical-feature-dist}.


```{r empirical-feature-dist, fig.cap = "Empirical feature distributions", fig.width = 8, fig.height = 4, out.width = ".8\\textwidth"}
tmp %>% 
  select(KM, cms, non_cms, matches, mismatches, D, ccf, H.H) %>%
  set_names(c("Matches", "CMS", "CNMS", "# Matches", "# Non-Matches", "D", "CCF", "H.H")) %>%
  mutate(Matches = ifelse(Matches, "Match (KM)", "Non-Match (KNM)")) %>%
  group_by(Matches) %>%
  sample_n(486) %>%
  ungroup() %>%
  gather(key = "key", value = "value", -Matches) %>%
  ggplot(aes(x = value, fill = Matches)) + 
  theme_bw() + 
  geom_density(color = "black", alpha = .75, adjust = 2) + 
  scale_fill_manual(values = c("Non-Match (KNM)" = "darkgrey", "Match (KM)" = "darkorange")) +
  facet_wrap(~key, scales = "free", ncol = 4) + 
  ylab("Density") + 
  theme(legend.position = c(1, 0), legend.justification = c(1, 0), axis.title.x = element_blank())
```
\autoref{fig:empirical-feature-dist} suggests that none of the seven features individually can discriminate between known matching and known non-matching pairs. This is because in every case there is significant overlap between the distributions of feature values among the matching and the non-matching pairs. \citet{hare2017algorithmic} proposed instead that features be combined into a single score using a random forest. A random forest is an ensemble supervised learning method for classification or regression based on the idea of decision trees \citep{breimanRandomForests2001}. For classification, the random forest is composed of many decision trees (500 or more) that are grown using bootstrap samples of the original data, and selecting a random subset of the features for each binary split.  The output the most likely class for each unit, and each unit is scored between 0 and 1, where larger scores denote a higher degree of similarity. Since the scores represent the average proportion of units of the predicted class in each terminal node, random forest scores can be thought of as the empirical probability of same class computed for each pair of images.


### From Land-to-land comparisons to Bullet-to-bullet comparisons
 
```{r, echo=FALSE, results = 'hide', warning = FALSE, message = FALSE}
features <- read.csv("data/H44-old-features.csv")

b12 <- features %>% filter(barrel1=="1", bullet1== "1",
                           barrel2=="1", bullet2== "2")
p1 <- b12 %>% ggplot(aes(x = land1, y = land2, fill = rfscore)) + 
  geom_tile() + ggtitle ("Same barrel") +  
  scale_fill_gradient2("RF score: ", midpoint=0.3, low = "darkgrey", high = "orange", limits=c(0,1)) +
  theme_bw() + 
  xlab ("Bullet 2") + ylab("Bullet 1") +
  theme(legend.position = "bottom") + coord_equal()

bab <- features %>% filter(barrel1=="1", bullet1== "1",
                           barrel2=="2", bullet2== "1")
p2 <- bab %>% ggplot(aes(x = land1, y = land2, fill = rfscore)) + 
  geom_tile() + ggtitle ("Different barrel") +  
  scale_fill_gradient2("RF score: ", midpoint=0.3, low = "darkgrey", high = "orange", limits=c(0,1)) +
  theme_bw() + 
  xlab ("Bullet 2") + ylab("Bullet 1") +
  theme(legend.position = "bottom") + coord_equal()
```



Land-land comparisons lead to a  set of scores for bullet-bullet comparisons. Figure \ref{fig:b2b} shows two matrices of scores for a pair of bullet-bullet matches. On the left, a matrix is shown that is typical for scores from two bullets from the same barrel. On the right, values for a pair of known non-matching bullets are shown.

```{r b2b, echo = FALSE, fig.width = 9, fig.height = 5,  out.width='.65\\textwidth', fig.cap="Overview of land-land matching scores for two pairs of bullet-bullet comparisons. On the left the two bullets are known to come from the same source (barrel) on the right, the bullets are from two different sources (barrels)"}
grid.arrange(p1, p2, ncol=2, padding=2)
```


When imaging bullets, operators scan one land at a time in a clockwise (left twisted rifling) or anti-clockwise (right twisted rifling) sequence. The order in which scans are acquired is kept as meta-information. Let us assume that lands on a bullet are labelled $\ell_i$ with $i = 1, .., p$. A match between two bullets therefore results in an expected additional $p-1$ matches between pairs of lands. These lands are also expected to be in a sequence, i.e. if there is a match between lands $\ell_i$ on bullet 1 and $\ell_j$ on bullet 2, we also expect lands $\ell_{i\oplus s}$ and $\ell_{j\oplus s}$ to match for all integers $s$, where $\oplus$ is defined as $a \oplus b \equiv \left((a + b)\mod p\right) + 1$. Here, the symbol $\mod()$ refers to the \emph{modulo} operator, which finds the remainder of the division of one number by another. This relationship gives rise to the sequence average maximum (SAM \citet{sam}, also known as "max phase" in \citet{chu:2010}) to quantify a bullet-to-bullet match:

#### Definition (Sequence Average and its Maximum)
Let $A$ be a square real-valued matrix of dimensions $p \times p$.
The $k$th \emph{sequence average} $SA(A, k)$ for $k = 0, ... p-1$ is defined  as 
$$SA(A, k) = \frac{1}{p} \sum_{i=1}^{p} a_{i,i \oplus k}, \text{ where } i\oplus k := \left((i + k)\mod p\right) + 1.$$
The \emph{Sequence Average Maximum} \citep[SAM, ][]{sam} of square matrix $R$ is defined as
$$SAM (R) = \max_{k = 1}^{p} SA(R, k).$$

```{r sam-sketch, out.width='\\textwidth', fig.width=14, fig.height = 4, fig.cap="Sketch of all six land-to-land sequences between two bullets with six lands. "}
df2 <- data.frame(expand.grid(x = 1:6, y = 1:6))
df2$case1 <- df2$x == ((df2$y+5) %% 6) + 1
df2$case2 <- df2$x == ((df2$y+0) %% 6) + 1
df2$case3 <- df2$x == ((df2$y+1) %% 6) + 1
df2$case4 <- df2$x == ((df2$y+2) %% 6) + 1
df2$case5 <- df2$x == ((df2$y+3) %% 6) + 1
df2$case6 <- df2$x == ((df2$y+4) %% 6) + 1

df2 %>% gather("case", "values", starts_with("case")) %>% 
  mutate(case = gsub("case", "", case)) %>%
  mutate(case = paste0("k = ", as.numeric(case)-1)) %>%
  ggplot(aes(x = factor(x), y = factor(y, levels=1:6), fill = values)) + 
  geom_tile(colour = "grey20") + 
  facet_wrap(~case, ncol = 6) +
  xlab("Bullet 2") + ylab("Bullet 1") +
  scale_x_discrete(labels = paste0("L",1:6)) +
  scale_y_discrete(labels = paste0("L",1:6)) +
  scale_fill_manual("Cell included in SA(A,k)", values = c("white", "grey20")) + 
  coord_equal() +
  theme(legend.position="bottom")
```

Looking back at Figure \ref{fig:b2b}, we see that for the two bullets from the same barrel, the sequence average for 
$k=2$ is higher than the other sequence averages, and also higher than the sequence averages for the other pair of bullets shown on the right of the figure.

### Results for the Hamby set of bullets

For the case of the Hamby bullets, the random forest produced a perfect classification of all pairs into the two classes. The separation between the values of the scores among known matching and known non-matching pairs was complete, as is shown in \autoref{fig:score-dist}.
```{r score-dist, fig.cap = "Random forest scores for the Hamby et al. (2009) known matching pairs of land engraved areas (dark blue) and known non-matching pairs (light blue).", fig.width = 8, fig.height = 4, out.width = ".8\\textwidth"}
f3nest %>% select(KM = KM_sam, sam_rf) %>%
  mutate(method = "Forest") %>%
  mutate(KM2 = c("KNM", "KM")[KM + 1] %>% as.factor()) %>%
  ggplot(aes(x = sam_rf, y = KM2, color = KM2, shape = KM2)) +
  facet_grid(method~.) +
  geom_jitter() +
  scale_color_manual(guide = F, values = c("KNM" = "darkgrey", "KM" = "darkorange")) +
  scale_shape_discrete(guide = F) +
  theme_bw() +
  theme(axis.title.y = element_blank()) +
  scale_x_continuous("Scores", limits = c(0, 1))
```

A limitation of all learning algorithms is that they depend critically on the data used to train them and they tend to over-fit the training data. Consequently, the algorithm’s performance when classifying a new set of units can be much worse and result in large mis-classification errors. This occurs when the minimizing the bias in the training data is the dominating criterion. To guard against over-fitting, it is possible to set aside a portion of the training data that can then be used as a test dataset, but even then, the mis-classification error tends to be under-estimated, albeit to a lower extent.

To explore whether the random forest fitted to the \citet{hamby2009} bullets has good classification performance when used to classify pairs of land engraved areas from bullets fired from other barrels or by guns of different make and model, and when the ammunition is also made by a different manufacturer, \citet{hare2017algorithmic} applied the model to thousands of pairs of known matching and known non-matching land engraved areas obtained from crime laboratories across the United States. Results have been promising; the random forest correctly determined every pair of bullets in every study when the gun barrel had conventional (rather than polygonal) rifling and striations were reasonably well marked, and when bullets were not coated with a polymer that flakes on contact with the barrel. 
 \autoref{fig:score-match-plot} shows the results observed in one such test set. Each pairwise comparison is represented as a square, with the center of the square shaded to represent the composite match score for the six lands on each bullet; the border of the square is colored orange if the bullets are from the same source. In the test set shown in \autoref{fig:score-match-plot}, there are three reference shots from each of eight barrels, and 10 fired rounds of unknown provenance. The test set was open, which means that it was possible that some of the test shots were not fired by any of the eight study barrels and that one or more of the barrels may have fired none of the 10 test shots; in this case, questioned bullets Q, Y, and Z did not originate from the 8 barrels in the study.
 

 

```{r score-match-plot, fig.cap = "Random forest scores of the similarity between 10 test shots and 24 reference shots from eight 9mm barrels.", out.width = ".8\\textwidth", fig.width = 8, fig.height = 3.5}
features <- read.csv("data/pd-features.csv.gz")
features <- features %>% mutate(
  lys = overlap*signature_length*1000/.645,
  cms = cms2 *lys*.645/1000
)
# change labels for land 3 and land 4 of bullet B3 in P7
features <- features %>% mutate(
  first = as.character(first),
  first = replace(first, first=="Gun 1-P7/B3/L4.dat", "XXX"),
  first = replace(first, first=="Gun 1-P7/B3/L3.dat", "Gun 1-P7/B3/L4.dat"),
  first = replace(first, first=="XXX", "Gun 1-P7/B3/L3.dat")
)

features <- features %>% mutate(
  KM = replace(KM, first %in% c("Gun 1-P7/B3/L3.dat", "Gun 1-P7/B3/L4.dat"), FALSE)
)
features <- features %>% mutate(
  KM = ifelse(first == "Gun 1-P7/B3/L3.dat", (second == "Unknown 1-J/L3.dat"), KM),
  KM = ifelse(first == "Gun 1-P7/B3/L4.dat", (second == "Unknown 1-J/L4.dat"), KM)
)



f2 <- features %>%
  separate(first, into = c("foo1", "foo2", "barrel1", "bullet1", "land1", "foo3"), remove = FALSE) %>%
  separate(second, into = c("foo4", "foo5", "bullet2", "land2", "foo6"), remove = FALSE) %>%
  select(-foo1, -foo2, -foo3, -foo4, -foo5, -foo6)


unknowns <- read.csv("data/pd-features-unknown.csv")
unknowns <- unknowns %>% filter(bullet1 != bullet2)
unknowns <- unknowns %>% mutate(
  bullet2 = gsub("Unknown 1-", "", bullet2),
  bullet1 = gsub("Unknown 1-", "", bullet1)
)
f3 <- rbind(
  f2 %>%
    select(
      b1, b2, barrel1, bullet1,
      land1, bullet2, land2, ccf, rfscore, cms, KM
    ) %>%
    mutate(barrel2 = "Unknown"),
  unknowns %>%
    select(
      b1, b2, bullet1,
      land1, bullet2, land2, ccf, rfscore, cms, 
    ) %>%
    mutate(barrel1 = "Unknown", barrel2 = "Unknown", KM = FALSE)
)

pdnest <- f3 %>% group_by(bullet2, barrel1, bullet1) %>% nest()

pdnest <- pdnest %>% mutate(
  sam_ccf = data %>% purrr::map_dbl(.f = function(d) {
    scores <- bulletxtrctr::compute_average_scores(d$land1, d$land2, d$ccf)
    max(scores)
  }),
  sam_rf = data %>% purrr::map_dbl(.f = function(d) {
    scores <- bulletxtrctr::compute_average_scores(d$land1, d$land2, d$rfscore)
    max(scores)
  }),
  KM = data %>% purrr::map_lgl(.f = function(d) {
    any(d$KM)
  }),
  sam_cms = data %>% purrr::map_dbl(.f = function(d) {
    scores <- bulletxtrctr::compute_average_scores(d$land1, d$land2, d$cms)
    max(scores)
  })
)

pdnest <- pdnest %>%
  mutate(
    bullet2 = factor(bullet2, levels = rev(c("N", "B", "E", "T", "H", "J", "K", "Q", "Y", "Z"))),
    bullet1 = factor(bullet1, levels = c("B1", "B2", "B3", rev(levels(bullet2))))
  )
p3 <- pdnest %>%
  ggplot(aes(y = bullet2, x = bullet1, fill = sam_rf)) +
  geom_tile(size = 1) +
  facet_grid(. ~ barrel1, scales = "free", space = "free") +
  ylab("Questioned bullets") +
  xlab("Known bullets and Questioned bullets") +
  scale_fill_gradient2("RF score ",
    low = "darkgrey",
    high = "darkorange", midpoint = 0.45, limits = c(0, 1)
  ) +
  scale_colour_manual("Same source", values = "darkorange") +
  scale_y_discrete() +
  theme_bw() +
  theme(legend.position = "bottom") +
   # coord_equal() +
  geom_tile(aes(colour = TRUE),
    size = .5,
    data = filter(pdnest, KM)
  ) +
  guides(colour = guide_legend(override.aes = list(fill = NA)))


pdnest$samesource <- pdnest$KM

p3
```

\citet{hare2017algorithmic} used a threshold of 0.5 for the SAM computed from the random forest score to categorize pairs of bullets into "same" and "different" gun. A row of three orange squares indicates that the corresponding questioned bullet matched all three of the reference shots fired by the barrel indicated in the column. In all cases, the algorithm classified the questioned bullets correctly. It correctly concluded, for example, that the last three questioned shots labeled $Q, Y, Z$ were not similar enough to any of the reference shots to declare a match, and that the barrel labeled $U10$ had not fired any of the questioned rounds.

The comparison method proposed by \citet{hare2017algorithmic} is promising, the method must undergo extensive additional testing and validation before it can be implemented in real casework. 
Researchers working on this type of problems have found that  the optimal score threshold for categorizing pairs of bullets as “same” or “different” varies from dataset to dataset. This may be a consequence of the fact that the random forest that \citet{hare2017algorithmic} have been applying to those sets of images was trained only once and only on a small training set. As more 3D images become available, it will be important to re-train the forest on a more diverse set that perhaps includes combinations of bullets and guns of the same caliber but manufactured by different companies.  This issue brings up a more general statistical question:  what are the factors that have an effect on the attributes of the striations that the gun imparts on a bullet and consequently, on the performance of the classification algorithm? It seems reasonable to speculate that physical properties such as the hardness of the inside of the barrel of the gun and of the bullet jacket might be important factors. Type of rifling and the degree of smoothness of the inside of the barrel are also likely to be factors that affect the characteristics of striations. To date, there have been no well-designed, appropriately powered studies to begin exploring some of these questions.
We note that fully automating the process is difficult, because the detection of the grooves is challenging. At this moment, it is still necessary to carefully check the automatically identified groove locations, which not only slows down the process but also increases the chances for errors. 
Finally, adoption of any new technology in working crime labs will require significant changes in protocols and in the way in which firearm examiners interpret and present their evidence. Thus, it is not likely that we will see these methodologies used in practice for several more years.


# Revisiting the question of source

The machine learning methods we have discussed to quantify the similarity between two items do not, by themselves, suffice to address the question of source. If a questioned bullet and a test shot from the suspect’s gun are similar, all we can say is that the suspect’s gun cannot be excluded as the source of the questioned bullet. To be able to conclude that the suspect’s gun and no other fired the questioned round, we would need to also show that the degree of similarity we observed is probative: we observed the same degree of similarity only when two bullets were fired from the same gun. The same type of reasoning applies to all other forms of evidence.

In the case of DNA profiles, we know that barring laboratory error, a match between two samples is probative, because no two individuals (except identical twins) have the same set of alleles at every marker. For fingerprints, it is also assumed that each person is born with an individual pattern, so that perfect prints from two different individuals should be distinguishable. For all other types of evidence, we have no means to compute a probative value, and therefore, we do not know whether a high degree of similarity between two items is indication or not of a common source. Until recently, forensic examiners in reports or testimony were able to focus on the similarity between two objects and conclude that high degree of similarity implied common source. But the blunders that led to questioning the validity of many forensic disciplines also led the public and the scientific community to revisit assumptions such as the uniqueness and repeatability of striations of rounds fired by a gun. As a result, juries and law professionals today are more likely to expect some discussion about the probative value of a "match" from forensic experts.

The probative value of evidence, or more precisely the \emph{weight of evidence}, can be estimated using a likelihood ratio \citep{lindley77, grove80}.  The likelihood ratio is a one-number summary of the probability of observing the evidence under the two competing hypotheses of same ($H_{ss}$) or different ($H_{ds}$) source. Let $E$ denote "evidence". Computation of the numerator $\mbox{Pr}(E|H_{ss})$ typically  involves information collected and analyzed in the process of the investigation.  The calculations required to quantify the denominator, on the other hand, are challenging, because they require information about the background population. This in turn raises other challenging questions including what is the relevant background population in each case, and whether available databases are representative of the specific background population.  

In the absence of a statistical model that may permit estimating the likelihood of a pattern under different assumptions about provenance, it may be possible to compute an empirical estimate of the frequency with which a given degree of similarity between two items can be expected when the items have a common source and when they do not. \autoref{fig:l2l-scores} illustrates this idea using firearms as an example.

```{r l2l-scores, fig.width = 8, fig.height = 4, out.width = ".8\\textwidth", fig.cap = "Empirical distributions of random forest scores for pairs of land engraved area scans known to have been produced from the same land (orange) and known to have originated from different lands (gray). The vertical lines in the top and bottom panels represent the score that was obtained when comparing a questioned with a reference scan of a land engraved area."}
# scores_all <- bind_rows(
#   data_frame(score=rbeta(10000, 2, 10), class = "Non-mates"),
#   data_frame(score=rbeta(10000, 4, 2), class = "Mates")
# )

sample_scores <- tibble(panel = c("Low score", "High score"), score = c(0.3, 0.8))

f3_plot <- f3 %>%
  mutate(KM = c("Non-mates", "Mates")[KM + 1])

# This uses land-to-land data because it's at least slightly more variable - bullet-to-bullet comparisons are so separated this calculation is not really feasible. 
ggplot() +
  geom_density(aes(rfscore, color = KM, fill=KM), data = f3_plot, alpha=0.5) +
  scale_fill_manual("", values = c("orange", "grey50")) + 
  scale_color_manual("", values = c("orange", "grey50")) + 
  geom_vline(aes(xintercept = score), data = sample_scores) + 
  facet_grid(panel~.) + 
  scale_x_continuous("Score") + 
  theme_bw() + 
  theme(axis.title.y = element_blank(), legend.position = c(1, 1), legend.justification = c(1, 1), legend.title = element_blank(), legend.background  = element_rect(fill = "transparent"))

```

```{r densities, fig.width = 8, fig.height = 3.5, fig.cap="Densities of known matches (orange) and known non-matches (grey) corresponding to all pair-wise land comparisons of the Hamby set.  The large grey points along the x axis mark three hypothetical scores a comparison might result in. The number in white inside the points gives the corresponding score-based likelihood ratio, indicating the likelihood to observe this score from a known match rather than a known non-match. ", out.width = ".8\\textwidth"}
tmpnest <- tmp %>% nest(-KM) %>% mutate(
  model = data %>% purrr::map(.f = function(d) {
    dens = density(d$ccf, from = 0, to = 1, n = 1001)
    data.frame(x = dens$x, y = dens$y)
  })
)

p <- tmp %>% 
  mutate(truth = c("Different source", "Same source")[KM+1]) %>%
  ggplot(aes(x = ccf)) +
  geom_density(aes(fill=truth), alpha = 0.6) +
  scale_fill_manual("", values = c("darkgrey", "darkorange")) +
  theme(legend.position = "top")

LRscores <- data.frame(x = c(0.4, 0.6, 0.8))
LRscores$KNM <- tmpnest$model[[1]]$y[which(tmpnest$model[[1]]$x %in% LRscores$x)]
LRscores$KM <- tmpnest$model[[2]]$y[which(tmpnest$model[[2]]$x %in% LRscores$x)]
LRscores$lr <- round(LRscores$KM/LRscores$KNM,1)
LRscores$ylabel <- pmax(LRscores$KM, LRscores$KNM)

p + 
  geom_line(data = tmpnest$model[[2]], 
            aes(x = x, y = y), size=1.25, colour="darkorange", fill=NA) +
  geom_line(data = tmpnest$model[[1]], 
            aes(x = x, y = y), size=1.25, colour="darkgrey", fill=NA) +
  xlab("Random forest score") +
  geom_segment(data = LRscores, aes(x=x, xend=x, y=0, yend=KNM), 
               colour="darkgrey", size = 1.25) +
  geom_segment(data = LRscores, aes(x=x, xend=x, y=0, yend=KM), 
               colour="darkorange", size = 1.25) +
  geom_point(data = LRscores, aes(x = x, y = 0), colour = "grey30", size = 15, alpha = 0.9) +
  geom_text(data=LRscores[-3,], aes(x = x, y = 0, label=lr), 
            colour = "grey90", size=4) +
  geom_text(data=LRscores[3,], aes(x = x, y = 0, label=lr), 
            colour = "grey90", size=4) +
  scale_y_continuous("Density", limits = c(-0.25, 4)) + 
  xlim(c(0,1)) + 
  theme(legend.position = c(1, 1), legend.justification = c(1, 1), legend.direction = "vertical", legend.title = element_blank())
```

The empirical distributions of similarity scores shown in orange and in gray in \autoref{fig:densities} represent the values of the score that could have been obtained when comparing bullets fired by the same or by different guns, respectively. Suppose that these distributions of scores were obtained from a very large number of pairs of bullets representing the population of guns and ammunition of a certain caliber. A crime is committed and a bullet is recovered from the scene. The suspect’s gun is test fired and the bullet in evidence is compared to the test shot using the algorithm that produced the background scores. Suppose that the resulting score is 0.8, as in  \autoref{fig:densities}. Visual inspection suggests that a score of 0.8 appears to be likely if the two bullets were fired from the same gun and unlikely otherwise. A \emph{score-based likelihood ratio} (SLR) is computed as the height of orange empirical density over the height of the grey distribution at 0.8, which in this example comes out to 371.4. The interpretation of this value is the following:  a score of 0.8 is about 370 more likely when two bullets (or cartridge cases) were fired from the same gun than when fired from different guns, so the score represents strong support for the same source proposition.  We could also calculate the probability of observing a score of 0.8 under each of the two empirical distributions. Regardless of the method, we would conclude that the two bullets were likely fired by the same gun. If instead the similarity score was 0.3, it would not be possible to reach a conclusion regarding source with any degree of confidence. The ratio of the heights of both distributions for a score of 0.3 is 0.3 indicating that it is about twice as likely to observe that score if bullets were fired by different guns, which is only weak evidence in favor of the hypothesis of different source. \citet{lund2017} and references therein discuss some potential limitations of score-based likelihood ratios to approximate model-based likelihood ratios.

The conclusion is that in order to assess the probative value of a match between two pieces of evidence, we need to have extensive background information about the population from which those two pieces of evidence might have originated. Thus, the construction of those reference databases must become a priority for the scientific community in general and for the forensics community in particular.

# Some final thoughts

The role of statistics in the evaluation and interpretation of bullet and cartridge case evidence has only recently become apparent. While the idea of moving toward a likelihood ratio framework for estimating the weight of evidence has gradually been accepted in several forensic disciplines (e.g., latent prints, handwriting, trace), this is not the case among firearm and toolmark examiners.  In part, this can be explained by the fact that we know very little about the factors that affect how striations are imparted on bullets and cartridge cases.  Consequently, we do not really know how to construct the reference populations of bullets and cartridge cases that are needed to calculate the appropriate denominator of the likelihood ratio in a specific case.

This chapter has focused on the promising approaches that have been proposed to quantify similarity between two bullets or two cartridge cases. Much of the progress has relied on the development and implementation of data science tools such as supervised learning algorithms. What so far has received less attention is the critical role that more traditional statistical tools including experimental design, sampling, two- or higher-dimensional functional analysis, and non-parametric models to represent, for example, the breech face impression on a cartridge case, can play in the construction of the likelihood ratio infrastructure in firearms and toolmark examination.

Consider again the calculation of the "probability of a coincidental match", or the denominator of the likelihood ratio. How should we determine what is the relevant background population for computing $\mbox{Pr}(E|H_{ds})$?  Suppose that the recovered gun in a crime scene is a 9mm Sig-Sauer P320 and the cartridge case corresponds to ammunition manufactured by Winchester. One approach to computing $\mbox{Pr}(E|H_{ds})$ is to base calculations on similarity scores among known matches and known non-matches obtained using exclusively Sig Sauer P320 guns and Winchester ammunition.  This approach necessitates the creation of a very large number of datasets, one for each possible combination of model of gun and make of ammunition.  A principled, potentially more efficient approach is to understand which gun and ammunition attributes result in comparable striations. With this information, we can then group gun/ammunition combinations and greatly reduce the number of different reference populations that need to be built and maintained. Understanding the factors that are associated with variability in striations of ammunition fired by the same or by different guns will require carefully designed experiments, that are adequately powered.

Machine learning has the potential to greatly improve the way in which forensic scientists evaluate pattern and other types of evidence. Yet much needs to be done before any of these new methods are ready for implementation in real casework. Serious limitations for further development include the dearth of data available to researchers, and the fact that collecting additional data in the form of 3D images of bullets and cartridge cases is both costly and time consuming.  Efforts including the  NIBD database maintained by NIST, which is growing and continues to be publicly available, are beginning to pay off in terms of attracting more researchers to work in this area. Organizations such as the Center for Statistics and Applications in Forensic Evidence (CSAFE; www.forensicstats.org), that put data and algorithms in the public domain, are also contributing to transparency and provide resources that enable independent research.  

No algorithm will completely replace humans in the analysis and interpretation of evidence, but with representative and large background databases, extensive testing, and validation, learning algorithms and other statistical tools can alleviate some of the subjectivity of forensic firearms examination as it is currently practiced and can serve to at least approximate the degree of uncertainty in forensic conclusions.

# References
